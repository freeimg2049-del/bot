import os
import requests
import threading
import telebot
import time
from flask import Flask
from collections import defaultdict
import sqlite3
from datetime import datetime, timedelta
import json

# --- FLASK APP CHO HEALTH CHECK ---
app = Flask(__name__)

@app.route('/')
def health_check():
    return {'status': 'Bot is running', 'timestamp': time.time()}

# --- PH·∫¶N 1: T·∫¢I C√ÅC BI·∫æN M√îI TR∆Ø·ªúNG ---
# L·∫•y Token c·ªßa Bot Telegram t·ª´ bi·∫øn m√¥i tr∆∞·ªùng
TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN")
# T·∫£i c√°c webhook chuy√™n d·ª•ng t·ª´ bi·∫øn m√¥i tr∆∞·ªùng
IMAGE_WEBHOOK_URL = os.getenv("IMAGE_WEBHOOK")
VIDEO_WEBHOOK_URL = os.getenv("VIDEO_WEBHOOK")
DOCS_WEBHOOK_URL = os.getenv("DOCS_WEBHOOK")

# Validation
if not TELEGRAM_TOKEN:
    raise ValueError("TELEGRAM_TOKEN environment variable is required")

# --- DATABASE SETUP ---
def init_database():
    """Kh·ªüi t·∫°o database SQLite ƒë·ªÉ l∆∞u analytics"""
    conn = sqlite3.connect('bot_analytics.db')
    conn.execute('''
        CREATE TABLE IF NOT EXISTS file_logs (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            user_id INTEGER NOT NULL,
            username TEXT,
            file_name TEXT,
            file_type TEXT,
            file_size INTEGER,
            pipeline_used TEXT,
            processed_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            status TEXT DEFAULT 'processing'
        )
    ''')
    
    conn.execute('''
        CREATE TABLE IF NOT EXISTS user_stats (
            user_id INTEGER PRIMARY KEY,
            username TEXT,
            total_files INTEGER DEFAULT 0,
            total_images INTEGER DEFAULT 0,
            total_videos INTEGER DEFAULT 0,
            total_documents INTEGER DEFAULT 0,
            total_size INTEGER DEFAULT 0,
            first_upload TIMESTAMP,
            last_upload TIMESTAMP
        )
    ''')
    conn.commit()
    conn.close()

def log_file_upload(user_id, username, file_name, file_type, file_size, pipeline):
    """Ghi log khi upload file"""
    conn = sqlite3.connect('bot_analytics.db')
    
    # Insert file log
    conn.execute('''
        INSERT INTO file_logs (user_id, username, file_name, file_type, file_size, pipeline_used)
        VALUES (?, ?, ?, ?, ?, ?)
    ''', (user_id, username, file_name, file_type, file_size, pipeline))
    
    # Update user stats
    conn.execute('''
        INSERT OR REPLACE INTO user_stats 
        (user_id, username, total_files, total_images, total_videos, total_documents, total_size, first_upload, last_upload)
        VALUES (
            ?,
            ?,
            COALESCE((SELECT total_files FROM user_stats WHERE user_id = ?), 0) + 1,
            COALESCE((SELECT total_images FROM user_stats WHERE user_id = ?), 0) + ?,
            COALESCE((SELECT total_videos FROM user_stats WHERE user_id = ?), 0) + ?,
            COALESCE((SELECT total_documents FROM user_stats WHERE user_id = ?), 0) + ?,
            COALESCE((SELECT total_size FROM user_stats WHERE user_id = ?), 0) + ?,
            COALESCE((SELECT first_upload FROM user_stats WHERE user_id = ?), ?),
            ?
        )
    ''', (
        user_id, username, user_id, user_id,
        1 if file_type == 'image' else 0,
        user_id,
        1 if file_type == 'video' else 0,
        user_id,
        1 if file_type == 'document' else 0,
        user_id, file_size,
        user_id, datetime.now(),
        datetime.now()
    ))
    
    conn.commit()
    conn.close()

def get_user_dashboard(user_id):
    """L·∫•y dashboard data cho user"""
    conn = sqlite3.connect('bot_analytics.db')
    cursor = conn.cursor()
    
    # Get user stats
    cursor.execute('SELECT * FROM user_stats WHERE user_id = ?', (user_id,))
    stats = cursor.fetchone()
    
    if not stats:
        return None
    
    # Get recent files (last 10)
    cursor.execute('''
        SELECT file_name, file_type, processed_at, status 
        FROM file_logs 
        WHERE user_id = ? 
        ORDER BY processed_at DESC 
        LIMIT 10
    ''', (user_id,))
    recent_files = cursor.fetchall()
    
    # Get today's stats
    today = datetime.now().date()
    cursor.execute('''
        SELECT COUNT(*), SUM(file_size) 
        FROM file_logs 
        WHERE user_id = ? AND DATE(processed_at) = ?
    ''', (user_id, today))
    today_stats = cursor.fetchone()
    
    # Get this week's stats
    week_ago = datetime.now() - timedelta(days=7)
    cursor.execute('''
        SELECT COUNT(*), SUM(file_size) 
        FROM file_logs 
        WHERE user_id = ? AND processed_at >= ?
    ''', (user_id, week_ago))
    week_stats = cursor.fetchone()
    
    conn.close()
    
    return {
        'total': {
            'files': stats[2],
            'images': stats[3], 
            'videos': stats[4],
            'documents': stats[5],
            'size': stats[6],
            'first_upload': stats[7],
            'last_upload': stats[8]
        },
        'today': {
            'files': today_stats[0] or 0,
            'size': today_stats[1] or 0
        },
        'week': {
            'files': week_stats[0] or 0,
            'size': week_stats[1] or 0
        },
        'recent_files': recent_files
    }

# Initialize database
init_database()

# Kh·ªüi t·∫°o bot
bot = telebot.TeleBot(TELEGRAM_TOKEN)
user_buffers = defaultdict(list)
buffer_timers = {}

# --- BATCH PROCESSING VARIABLES ---
# --- PH·∫¶N 2: H√ÄM G·ªåI PIPEDREAM TRONG N·ªÄN ---
def call_pipedream_in_background(target_webhook, payload, user_id=None, file_count=1, file_info=None):
    """
    H√†m n√†y ch·∫°y trong m·ªôt lu·ªìng ri√™ng ƒë·ªÉ g·ªçi Pipedream.
    N√≥ kh√¥ng ·∫£nh h∆∞·ªüng ƒë·∫øn lu·ªìng ch√≠nh ƒëang tr·∫£ l·ªùi Telegram.
    """
    print(f"B·∫Øt ƒë·∫ßu g·ªçi Pipedream trong n·ªÅn t·ªõi: {target_webhook}")
    try:
        # G·ª≠i y√™u c·∫ßu POST v·ªõi d·ªØ li·ªáu JSON, ƒë·∫∑t timeout 15 gi√¢y ƒë·ªÉ tr√°nh treo
        response = requests.post(target_webhook, json=payload, timeout=15)
        response.raise_for_status()
        print(f"G·ªçi Pipedream trong n·ªÅn th√†nh c√¥ng. Status: {response.status_code}")
        
        # Update database status to success
        if file_info:
            conn = sqlite3.connect('bot_analytics.db')
            conn.execute('''
                UPDATE file_logs 
                SET status = 'success' 
                WHERE user_id = ? AND file_name = ? AND processed_at = (
                    SELECT MAX(processed_at) FROM file_logs 
                    WHERE user_id = ? AND file_name = ?
                )
            ''', (user_id, file_info['name'], user_id, file_info['name']))
            conn.commit()
            conn.close()
        
        # Optional: Notify completion for single files
        if user_id and file_count == 1:
            try:
                bot.send_message(user_id, "‚úÖ File ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω th√†nh c√¥ng!")
            except:
                pass  # Ignore notification errors
                
    except requests.exceptions.RequestException as e:
        print(f"L·ªói khi g·ªçi Pipedream trong n·ªÅn: {e}")
        
        # Update database status to failed
        if file_info:
            conn = sqlite3.connect('bot_analytics.db')
            conn.execute('''
                UPDATE file_logs 
                SET status = 'failed' 
                WHERE user_id = ? AND file_name = ? AND processed_at = (
                    SELECT MAX(processed_at) FROM file_logs 
                    WHERE user_id = ? AND file_name = ?
                )
            ''', (user_id, file_info['name'], user_id, file_info['name']))
            conn.commit()
            conn.close()
            
        if user_id:
            try:
                bot.send_message(user_id, "‚ùå C√≥ l·ªói x·∫£y ra khi x·ª≠ l√Ω file")
            except:
                pass

# --- BATCH PROCESSING FUNCTION ---
def process_batch(user_id):
    """X·ª≠ l√Ω batch files c·ªßa user"""
    if user_id not in user_buffers:
        return
        
    files = user_buffers[user_id].copy()
    user_buffers[user_id].clear()
    
    if not files:
        return
    
    print(f"Processing batch of {len(files)} files for user {user_id}")
    
    # Notify user about batch
    try:
        bot.send_message(user_id, f"üì¶ ƒêang x·ª≠ l√Ω {len(files)} files...")
    except:
        pass
    
    # Process each file
    for message in files:
        target_webhook = None
        file_type = ""
        pipeline = ""
        
        # Get file info
        file_info = {}
        if message.photo:
            target_webhook = IMAGE_WEBHOOK_URL
            file_type = "image"
            pipeline = "images"
            # Get largest photo size
            photo = max(message.photo, key=lambda x: x.file_size)
            file_info = {
                'name': f"photo_{photo.file_id}.jpg",
                'size': photo.file_size or 0
            }
        elif message.video:
            target_webhook = VIDEO_WEBHOOK_URL
            file_type = "video" 
            pipeline = "videos"
            file_info = {
                'name': message.video.file_name or f"video_{message.video.file_id}",
                'size': message.video.file_size or 0
            }
        elif message.document:
            target_webhook = DOCS_WEBHOOK_URL
            file_type = "document"
            pipeline = "documents"
            file_info = {
                'name': message.document.file_name or f"document_{message.document.file_id}",
                'size': message.document.file_size or 0
            }
            
        if target_webhook and file_info:
            # Log to database
            username = message.from_user.username or message.from_user.first_name or "Unknown"
            log_file_upload(user_id, username, file_info['name'], file_type, file_info['size'], pipeline)
            
            # Process in background thread
            thread = threading.Thread(
                target=call_pipedream_in_background, 
                args=(target_webhook, message.json, user_id, len(files), file_info)
            )
            thread.daemon = True
            thread.start()

# --- PH·∫¶N 3: H√ÄM X·ª¨ L√ù CH√çNH KHI NH·∫¨N FILE ---
@bot.message_handler(content_types=['photo', 'video', 'document'])
def handle_file_with_batching(message):
    """
    X·ª≠ l√Ω file v·ªõi batching ƒë·ªÉ tr√°nh spam notifications
    """
    user_id = message.from_user.id
    
    # Validate webhooks
    target_webhook = None
    if message.photo and IMAGE_WEBHOOK_URL:
        target_webhook = IMAGE_WEBHOOK_URL
    elif message.video and VIDEO_WEBHOOK_URL:
        target_webhook = VIDEO_WEBHOOK_URL
    elif message.document and DOCS_WEBHOOK_URL:
        target_webhook = DOCS_WEBHOOK_URL
    
    if not target_webhook:
        bot.reply_to(message, "‚ùå Lo·∫°i file n√†y kh√¥ng ƒë∆∞·ª£c h·ªó tr·ª£ ho·∫∑c ch∆∞a c·∫•u h√¨nh webhook.")
        return
    
    # Add to user buffer
    user_buffers[user_id].append(message)
    
    # Cancel existing timer
    if user_id in buffer_timers:
        buffer_timers[user_id].cancel()
    
    # Set new timer (3 seconds delay)
    timer = threading.Timer(3.0, lambda: process_batch(user_id))
    buffer_timers[user_id] = timer
    timer.start()

# --- DASHBOARD COMMANDS ---
@bot.message_handler(commands=['dashboard', 'stats'])
def show_dashboard(message):
    """Hi·ªÉn th·ªã dashboard analytics cho user"""
    user_id = message.from_user.id
    dashboard_data = get_user_dashboard(user_id)
    
    if not dashboard_data:
        bot.reply_to(message, "üìä Ch∆∞a c√≥ d·ªØ li·ªáu. H√£y upload file ƒë·∫ßu ti√™n!")
        return
    
    # Format file size
    def format_size(size_bytes):
        if size_bytes == 0:
            return "0 B"
        for unit in ['B', 'KB', 'MB', 'GB']:
            if size_bytes < 1024:
                return f"{size_bytes:.1f} {unit}"
            size_bytes /= 1024
        return f"{size_bytes:.1f} TB"
    
    total = dashboard_data['total']
    today = dashboard_data['today']
    week = dashboard_data['week']
    
    # Create dashboard text
    dashboard_text = f"""
üìä **YOUR DASHBOARD**

**üìà T·ªîNG QUAN**
üìÅ T·ªïng files: **{total['files']}**
üì∑ ·∫¢nh: {total['images']} files
üé• Video: {total['videos']} files  
üìÑ Documents: {total['documents']} files
üíæ T·ªïng dung l∆∞·ª£ng: **{format_size(total['size'])}**

**üìÖ H√îM NAY**
üì§ Upload: {today['files']} files ({format_size(today['size'])})

**üìä TU·∫¶N N√ÄY** 
üìà Upload: {week['files']} files ({format_size(week['size'])})

**‚è∞ TH·ªúI GIAN**
üöÄ L·∫ßn ƒë·∫ßu: {total['first_upload'][:16] if total['first_upload'] else 'N/A'}
üïí G·∫ßn nh·∫•t: {total['last_upload'][:16] if total['last_upload'] else 'N/A'}

S·ª≠ d·ª•ng /recent ƒë·ªÉ xem files g·∫ßn ƒë√¢y
S·ª≠ d·ª•ng /search <t√™n file> ƒë·ªÉ t√¨m ki·∫øm
    """
    
    bot.reply_to(message, dashboard_text, parse_mode='Markdown')

@bot.message_handler(commands=['recent'])
def show_recent_files(message):
    """Hi·ªÉn th·ªã files g·∫ßn ƒë√¢y"""
    user_id = message.from_user.id
    dashboard_data = get_user_dashboard(user_id)
    
    if not dashboard_data or not dashboard_data['recent_files']:
        bot.reply_to(message, "üìù Kh√¥ng c√≥ files g·∫ßn ƒë√¢y")
        return
    
    recent_text = "üìù **FILES G·∫¶N ƒê√ÇY** (10 files m·ªõi nh·∫•t)\n\n"
    
    for i, (file_name, file_type, processed_at, status) in enumerate(dashboard_data['recent_files'], 1):
        status_emoji = "‚úÖ" if status == "success" else "‚ùå" if status == "failed" else "‚è≥"
        type_emoji = {"image": "üì∑", "video": "üé•", "document": "üìÑ"}.get(file_type, "üìÅ")
        
        # Shorten long filenames
        display_name = file_name[:30] + "..." if len(file_name) > 30 else file_name
        time_str = processed_at[:16]  # YYYY-MM-DD HH:MM
        
        recent_text += f"{i}. {type_emoji} {display_name}\n"
        recent_text += f"   {status_emoji} {time_str}\n\n"
    
    bot.reply_to(message, recent_text, parse_mode='Markdown')

@bot.message_handler(commands=['search'])
def search_files(message):
    """T√¨m ki·∫øm files theo t√™n"""
    user_id = message.from_user.id
    
    # Get search query
    command_parts = message.text.split(' ', 1)
    if len(command_parts) < 2:
        bot.reply_to(message, "üí° S·ª≠ d·ª•ng: /search <t√™n file>")
        return
    
    search_query = command_parts[1].strip()
    
    # Search in database
    conn = sqlite3.connect('bot_analytics.db')
    cursor = conn.cursor()
    
    cursor.execute('''
        SELECT file_name, file_type, processed_at, status 
        FROM file_logs 
        WHERE user_id = ? AND file_name LIKE ? 
        ORDER BY processed_at DESC 
        LIMIT 20
    ''', (user_id, f'%{search_query}%'))
    
    results = cursor.fetchall()
    conn.close()
    
    if not results:
        bot.reply_to(message, f"üîç Kh√¥ng t√¨m th·∫•y file n√†o ch·ª©a '{search_query}'")
        return
    
    search_text = f"üîç **K·∫æT QU·∫¢ T√åM KI·∫æM** '{search_query}'\n\n"
    
    for i, (file_name, file_type, processed_at, status) in enumerate(results, 1):
        status_emoji = "‚úÖ" if status == "success" else "‚ùå" if status == "failed" else "‚è≥"
        type_emoji = {"image": "üì∑", "video": "üé•", "document": "üìÑ"}.get(file_type, "üìÅ")
        
        display_name = file_name[:40] + "..." if len(file_name) > 40 else file_name
        time_str = processed_at[:16]
        
        search_text += f"{i}. {type_emoji} {display_name}\n"
        search_text += f"   {status_emoji} {time_str}\n\n"
    
    search_text += f"\nT√¨m th·∫•y {len(results)} file(s)"
    
    bot.reply_to(message, search_text, parse_mode='Markdown')
@bot.message_handler(commands=['start', 'help'])
def send_welcome(message):
    welcome_text = """
ü§ñ **File Manager Bot**

G·ª≠i file ƒë·ªÉ t√¥i t·ª± ƒë·ªông ph√¢n lo·∫°i v√† l∆∞u tr·ªØ:
üì∑ ·∫¢nh ‚Üí Image Pipeline
üé• Video ‚Üí Video Pipeline  
üìÑ Documents ‚Üí Document Pipeline

**Commands:**
/start - Hi·ªÉn th·ªã tin nh·∫Øn n√†y
/help - H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng
/status - Ki·ªÉm tra tr·∫°ng th√°i bot

Bot s·∫Ω t·ª± ƒë·ªông group c√°c files li√™n t·ª•c ƒë·ªÉ tr√°nh spam th√¥ng b√°o! ‚ú®
    """
    bot.reply_to(message, welcome_text, parse_mode='Markdown')

@bot.message_handler(commands=['status'])
def check_status(message):
    status_text = f"""
üìä **Bot Status**

üîó **Webhooks configured:**
üì∑ Images: {'‚úÖ' if IMAGE_WEBHOOK_URL else '‚ùå'}
üé• Videos: {'‚úÖ' if VIDEO_WEBHOOK_URL else '‚ùå'} 
üìÑ Documents: {'‚úÖ' if DOCS_WEBHOOK_URL else '‚ùå'}

‚ö° Bot is running and ready to process files!
    """
    bot.reply_to(message, status_text, parse_mode='Markdown')

# --- ERROR HANDLER ---
def error_handler(message):
    print(f"Error in message handling: {message}")

# --- PH·∫¶N 4: KH·ªûI CH·∫†Y BOT ---
if __name__ == "__main__":
    print("üöÄ Bot ƒëang kh·ªüi ƒë·ªông...")
    print(f"‚úÖ Token configured: {'Yes' if TELEGRAM_TOKEN else 'No'}")
    print(f"üì∑ Image webhook: {'Yes' if IMAGE_WEBHOOK_URL else 'No'}")
    print(f"üé• Video webhook: {'Yes' if VIDEO_WEBHOOK_URL else 'No'}")
    print(f"üìÑ Docs webhook: {'Yes' if DOCS_WEBHOOK_URL else 'No'}")
    
    # Start Flask in separate thread for health checks
    flask_thread = threading.Thread(target=lambda: app.run(host='0.0.0.0', port=int(os.getenv('PORT', 5000))))
    flask_thread.daemon = True
    flask_thread.start()
    
    print("‚úÖ Bot ready! Starting polling...")
    
    # Start bot with error handling
    try:
        bot.polling(none_stop=True, interval=0, timeout=20)
    except Exception as e:
        print(f"‚ùå Bot error: {e}")
        time.sleep(15)
        # Restart polling
        bot.polling(none_stop=True, interval=0, timeout=20)